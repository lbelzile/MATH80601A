
# Computational strategies and diagnostics


```{r}
#| label: setup
#| file: "_common.R"
#| include: true
#| message: false
#| warning: false
#| echo: false
```

The Bayesian workflow is a coherent framework for model formulation construction, inference and validation. It typically involves trying and comparing different models, adapting and modifying these models [@Gelman:2020]; see also [Michael Betancourt](https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html) for excellent visualizations. In this chapter, we focus on three aspects of the workflow: model validation, evaluation and comparison.

::: {.callout-important}

## **Learning objectives**:

At the end of the chapter, students should be able to

- use output of MCMC to obtain estimates and standard errors.
- choose suitable test statistics to evaluate model adequacy.
- assess convergence using graphical tools and effective sample size.
- perform model comparisons using Bayes factor or predictive measures.
- diagnose performance of MCMC algorithms (in terms of mixing and effective sample size).
- implement strategies to improve sampling performance, including block updates, reparametrization and marginalization.


:::

    



For a given problem, there are many different Markov chain Monte Carlo algorithms that one can implement: they will typically be distinguished based on the running time per iteration and the efficiency of the samplers, with algorithms providing realizations of Markov chains with lower autocorrelation being preferred. Many visual diagnostics and standard tests can be used to diagnose lack of convergence, or inefficiency. The purpose of this section is to review these in turn, and to go over tricks that can improve mixing.



<!--
**Prior to posterior**: prior sensitivity requires to rerun the algorithm with different priors, but it is sometimes feasible in simpler models to simply use a fast Gaussian approximation via the maximum a posteriori, and generate from the latter, to assess the impact of the prior. We can compare posterior density with prior density. The general rule is that parameters far from the data layer are more impacted by the prior choice.
-->

<!-- A modular approach to model building is recommended. It is a good strategy to start small, with a toy model, and to complexify until the fit is adequate. The modular approach can also help to diagnose convergence problems, bugs and identifiability problems.  -->

**Generating artificial data**: Some problems and checks relate to models and the correct implementations (of the algorithms). Sometimes, the probabilistic procedure will generate draws, but it's unclear whether our numerical implementation is correct. We can sometimes see this if the output is truly misleading, but it's not always obvious. We can for example generate an "artificial" or fake data set from the model with some fixed parameter inputs to see if we can recover the parameter values used to generate these within some credible set. 

Many such sanity checks can be implemented by means of simulations. Consider prior predictive checks: if the prior has a distribution from which we can generate, we can obtain prior draws from $p(\boldsymbol{\theta})$, generate data from the prior predictive $p(y \mid \boldsymbol{\theta})$ by simulating new observations from the data generating mechanism of the likelihood, and use these to obtain prior predictive by removing the likelihood component altogether: the draws from the prior predictive should then match posterior draws with only the prior. 

The "data-averaged posterior" is obtained upon noting that [@Geweke:2004]
\begin{align*}
p(\boldsymbol{\theta}) = \int \int_{\boldsymbol{\Theta}} p( \boldsymbol{\theta} \mid \boldsymbol{y}) p(\boldsymbol{y} \mid \widetilde{\boldsymbol{\theta}}) p(\widetilde{\boldsymbol{\theta}}) \mathrm{d} \widetilde{\boldsymbol{\theta}} \mathrm{d} \boldsymbol{y}
\end{align*}
by forward sampling first the prior, than data for this particular value and obtaining the posterior associated with the latter. 

We can test that our sampling algorithm correctly samples from the posterior distribution of interest by running the following procedure, which is however computationally intensive.

:::{#prp-sbc}

## Simulation based calibration

Simulation-based calibration  [@Talts:2020] proceeds with, in order 

1. $\boldsymbol{\theta}_0 \sim p(\boldsymbol{\theta}),$
2. $\boldsymbol{y}_0 \sim p(\boldsymbol{y} \mid \boldsymbol{\theta}_0),$
3. $\boldsymbol{\theta}_1, \ldots, \boldsymbol{\theta}_B \sim p(\boldsymbol{\theta} \mid \boldsymbol{y}_0 ).$


Conditional on the simulated $\boldsymbol{y}$, the distribution of $\boldsymbol{\theta}_0$ is the same as that of $\boldsymbol{\theta}_1, \ldots, \boldsymbol{\theta}_B.$ We do a dimension reduction step taking the test function $t(\cdot)$ to get the rank of the prior draw among the posterior ones, breaking ties at random if any. In the absence of ties,
\begin{align*}
T = \sum_{b=1}^B \mathrm{I}\{t(\boldsymbol{\theta}_b, \boldsymbol{y}) < t(\boldsymbol{\theta}_0,\boldsymbol{y})\},
\end{align*}

These steps are repeated $K$ times, yielding $K$ test functions $T_1, \ldots, T_K.$ We then test for uniformity using results from @Sailynoja:2022.

:::



## Convergence diagnostics and model validation

Many diagnostics rely on running multiple Markov chains for the same problem, with different starting values. 
In practice, it is more efficient to run a single long chain than multiple chains, because of the additional computational overhead related to burn in and warmup period. Running multiple chains however has the benefit of allowing one to compute diagnostics of convergence (by comparing chains) such as $\widehat{R},$ and to detect local modes.


:::{#def-traceplots}

## Trace plots

A trace plot is a line plot of the Markov chain as a function of the number of iterations. It should be stable around some values if the posterior is unimodal and the chain has reached stationarity. The ideal shape is that of a 'fat hairy catterpilar'.

:::

It is useful to inspect visually the Markov chain, as it may indicate several problems. If the chain drifts around without stabilizing around the posterior mode, then we can suspect that it hasn't reached it's stationary distribution (likely due to poor starting values). In such cases, we need to disregard the dubious draws from the chain by discarding the so-called warm up or **burn in** period. While there are some guarantees of convergence in the long term, silly starting values may translate into tens of thousands of iterations lost wandering around in regions with low posterior mass. Preliminary optimization and plausible starting values help alleviate these problems. @fig-badstart shows the effect of bad starting values on a toy problem where convergence to the mode is relatively fast. If the proposal is in a flat region of the space, it can wander around for a very long time before converging to the stationary distribution.



:::{#def-trankplot}

## Trace rank plot

If we run several chains, as in @fig-badstart, with different starting values, we can monitor convergence by checking whether these chains converge to the same target. A **trace rank** plot compares the rank of the values of the different chain at a given iteration: with good mixing, the ranks should switch frequently and be distributed uniformly across integers.

:::

A trace rank plot is shown on right panel of @fig-badstart.

```{r}
#| eval: true
#| echo: false
#| label: fig-badstart
#| fig-cap: "Traceplots of three Markov chains for the same target with different initial values for the first 500 iterations (left) and trace rank plot after discarding these (right)."
set.seed(80601)
niter <- 2500
fakesamp <- rnorm(n = 20, mean = 1, sd = 2)
fn <- function(par){ sum(dnorm(fakesamp, mean = par, sd = 2, log = TRUE))}
chain1 <- matrix(nrow = niter, ncol = 1)
colnames(chain1) <- "beta"
chain2 <- chain3 <-  chain1
cur <- c(-50, 10, 0)
for(i in seq_len(niter)){
  chain1[i,1] <- mgp::mh.fun(cur = cur[1], lb = -Inf, ub = Inf, prior.fun = identity, lik.fun = fn, pcov = matrix(0.3), cond = FALSE, transform = FALSE)$cur
  chain2[i,1] <- mgp::mh.fun(cur = cur[2], lb = -Inf, ub = Inf, prior.fun = identity, lik.fun = fn, pcov = matrix(0.3), cond = FALSE, transform = FALSE)$cur
  chain3[i,1] <- mgp::mh.fun(cur = cur[3], lb = -Inf, ub = Inf, prior.fun = identity, lik.fun = fn, pcov = matrix(0.3), cond = FALSE, transform = FALSE)$cur
  cur <- c(chain1[i,1], chain2[i,1], chain3[i,1])
}
# coda::traceplot(coda::as.mcmc(chains_goldi))
bayesplot::color_scheme_set("darkgray")
mcmc_list <- coda::mcmc.list(
  coda::mcmc(chain1),
  coda::mcmc(chain2),
  coda::mcmc(chain3))
mcmc_list2 <- coda::mcmc.list(
  coda::mcmc(chain1[-(1:500),,drop = FALSE]),
  coda::mcmc(chain2[-(1:500),,drop = FALSE]),
  coda::mcmc(chain3[-(1:500),,drop = FALSE]))
g1 <- bayesplot::mcmc_trace(
  x = mcmc_list,
  n_warmup = 0,window = c(1,500)) +
  labs(y = "") +
  theme_classic() +
  theme(legend.position = "none")
g2 <- bayesplot::mcmc_rank_overlay(
  x = mcmc_list2) +
  labs(y = "") +
  theme_classic() +
  theme(legend.position = "none")
g1 + g2
```



```{r}
#| eval: true
#| echo: false
#| warning: false
#| message: false
#| cache: true
#| include: false
#| label: fit-modelsimple
library(cmdstanr)
data(smartwatch, package = "hecbayes")
pois_simple <- cmdstanr::cmdstan_model(stan_file = "models/poisson_simple.stan")
postsamps <- pois_simple $sample(data = with(
  smartwatch,
  list(N = length(nviolation),
       K = length(levels(task)),
       y = as.integer(nviolation),
       fixed = as.integer(task))),
  iter_warmup = 1000,
  iter_sampling = 10000,
  chains = 1,
  refresh = 0L,
  output_dir = "models",
  output_basename = "Poisson_simple",
  show_messages = FALSE)
data(smartwatch, package = "hecbayes")
output1 <- cmdstanr::read_cmdstan_csv("models/Poisson_mixed3-1.csv")[["post_warmup_draws"]]
output2 <- cmdstanr::read_cmdstan_csv("models/Poisson_simple-1.csv")[["post_warmup_draws"]]
coef_beta <- paste0("beta[",as.integer(smartwatch$task),"]")
id_beta <- match(coef_beta, dimnames(output1)[[3]])
coef_alpha <- paste0("alpha[",as.integer(smartwatch$id),"]")
id_alpha <- match(coef_alpha, dimnames(output1)[[3]])
B <- dim(output1)[1]
n <- nrow(smartwatch)
loglik_pt1 <- matrix(nrow = B, ncol = n)
postpred1 <- matrix(nrow = B, ncol = n)
for(b in seq_len(B)){
loglik_pt1[b,] <- dpois(
  x = smartwatch$nviolation,
  lambda = exp(output1[b,1,id_alpha] + output1[b,1,id_beta]),
  log = TRUE)
postpred1[b,] <- rpois(
  n = n,
  lambda = exp(output1[b,1,id_alpha] + output1[b,1,id_beta]))
}
B2 <- dim(output2)[1]
id_beta <- match(coef_beta, dimnames(output2)[[3]])
loglik_pt2 <- matrix(nrow = B2, ncol = n)
postpred2 <- matrix(nrow = B2, ncol = n)
for(b in seq_len(B2)){
loglik_pt2[b,] <- dpois(
  x = smartwatch$nviolation,
  lambda = exp(output2[b,1,id_beta]),
  log = TRUE)
postpred2[b,] <- rpois(
  n = n,
  lambda = exp(output2[b,1,id_beta]))
}

```

:::{#def-burnin}

## Burn in period

We term "burn in" the initial steps of the MCMC algorithm that are discarded because the chain has not reached it's stationary distribution, due to poor starting values. , but visual inspection using a trace plot may show that it is necessary to remove additional observations. 

:::

Most software will remove the first $N$ initial values (typically one thousand). Good starting values can reduce the need for a long burn in period. If visual inspection of the chains reveal that some of the chains for one or more parameters are not stationary until some iteration, we will discard all of these in addition. @Geweke:1992's test measure whether the distribution of the resulting Markov chain is the same at the beginning and at the end through a test of equality of means.

:::{#def-warmup}

## Warmup

Warmup period refers to the initial sampling phase (potentially overlapping with burn in period) during which proposals are tuned (for example, by changing the variance proposal to ensure good acceptance rate or for Hamiltonian Monte Carlo (HMC) to tune the size of the leapfrog.
These initial steps should be disregarded.

:::



:::{#rmk-short-vs-long}

## Multiple short chains or longer runs?

In principle, it is more efficient to run a single Markov chain to draw samples for longer than multiple (shorter chains) for a fixed computational budget. Indeed, a single run means warmup needs to be achieve once. The benefits of running multiple chains comes from different considerations: we can monitor convergence to the stationary distribution (or to different modes for multimodal posteriors), and run diagnostics that rely on between-chain variance. Multiple chains can also be run in parallel and the results combined, a situation more in line with modern computer architecture.

:::

The target of inference is a functional (i.e., one-dimensional summaries of the chain): we need to have convergence of the latter, but also sufficient effective sample size for our averages to be accurate (at least to two significant digits).

```{r}
#| label: get-results
#| eval: true
#| echo: false
#| message: false
#| warning: false
class(output1) <- class(output2) <- "array"
ess1 <- floor(coda::effectiveSize(coda::as.mcmc(output1[,1,-1])))
ess2 <- floor(coda::effectiveSize(coda::as.mcmc(output2[,1,-1])))
```



To illustrate these, we revisit the model from @exm-randomeffects with a penalized complexity prior for the individual effect $\alpha_i$ and vague normal priors. We also fit a simple Poisson model with only the fixed effect, taking $Y_{ij} \sim \mathsf{Poisson}\{\exp(\beta_j)\}$ with $\beta_j \sim \mathsf{Gauss}(0,100)$. This model has too little variability relative to the observations and fits poorly as is.


For the Poisson example, the effective sample size for the $\boldsymbol{\beta}$ for the multilevel model is a bit higher than 1000 with $B=5000$ iterations, whereas we have for the simple naive model is $`r round(min(ess2),digits = 0)`$ for $B=10000$ draws, suggesting superefficient sampling. The dependency between $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$ is responsible for the drop in accuracy.

The `coda` (convergence diagnosis and output analysis) **R** package [@coda] contains many tests. For example, the Geweke $Z$-score compares the averages for the beginning and the end of the chain: rejection of the null implies lack of convergence, or poor mixing.


Running multiple Markov chains can be useful for diagnostics.

:::{#prp-rhat}

## Gelman--Rubin diagnostic

The Gelman--Rubin diagnostic $\widehat{R},$ introduced in @Gelman.Rubin:1992 and also called potential scale reduction statistic, is obtained by considering the difference between within-chains and between-chains variance. Suppose we run $M$ chains for $B$ iterations, post burn in. Denoting by $\theta_{bm}$ the $b$th draw of the $m$th chain, we compute the global average $\overline{\theta} = B^{-1}M^{-1}\sum_{b=1}^B \sum_{m=1}^m \theta_{bm}$ and similarly the chain sample average and variances, respectively $\overline{\theta}_m$ and $\widehat{\sigma}^2_m$ ($m=1, \ldots, M$). The between-chain variance and within-chain variance estimator are
\begin{align*}
\mathsf{Va}_{\text{between}} &= \frac{B}{M-1}\sum_{m=1}^M (\overline{\theta}_m - \overline{\theta})^2\\
\mathsf{Va}_{\text{within}} &= \frac{1}{M}\sum_{m=1}^M \widehat{\sigma}^2_m
\end{align*}
and we can compute
\begin{align*}
\widehat{R} = \left(\frac{\mathsf{Va}_{\text{within}}(B-1) + \mathsf{Va}_{\text{between}}}{B\mathsf{Va}_{\text{within}}}\right)^{1/2}
\end{align*}
The potential scale reduction statistic must be, by construction, larger than 1 in large sample. Any value larger than this is indicative of problems of convergence. While the Gelman--Rubin diagnostic is frequently reported, and any value larger than 1 deemed problematic, it is not enough to have approximately $\widehat{R}=1$ to guarantee convergence, but large values are usually indication of something being amiss. @fig-rhat shows two instances where the chains are visually very far from having the same average and this is reflected by the large values of $\widehat{R}.$
:::

```{r}
#| eval: true
#| echo: false
#| label: fig-rhat
#| fig-cap: "Two pairs of Markov chains: the top ones seem stationary, but with different modes. This makes the between chain variance substantial, with a value of $\\widehat{R} \\approx 3.4,$ whereas the chains on the right hover around the same values of zero, but do not appear stable with $\\widehat{R} \\approx 1.6.$"
B <- 1000
set.seed(1234)
c1 <- arima.sim(model = list(ar = c(0.6,0.2)),
                           rand.gen = rexp,
                           n = B) + -2
c2 <- arima.sim(model = list(ar = c(0.5,0.2)),
                           n = B) - 1
chains <- coda::mcmc.list(
  list(theta = coda::mcmc(c1),
       theta = coda::mcmc(c2)))
rhat1 <- coda::gelman.diag(chains)
# bayesplot::mcmc_trace(chains)

g1 <- ggplot(data = data.frame(
    time = rep(seq_len(B), length.out = 2*B),
    chain = c(c1, c2),
    group = factor(rep(c(1,2), each = B))),
  mapping = aes(x = time, y = chain, col = group)) +
  geom_line() +
  scale_color_manual(values = MetBrewer::met.brewer("Renoir", 3)[c(2:3)]) +
  labs(x = "iteration number", y = "") +
  theme_classic() +
  theme(legend.position = "none")

set.seed(1234)
c1b <- arima.sim(model = list(ar = c(0.6,0.2)),
                rand.gen = rnorm,
                n = B) + seq(-2, 2, length.out = B)
c2b <- arima.sim(model = list(ar = c(0.5,0.2)),
                n = B) +  seq(2, -2, length.out = B)
chains <- coda::mcmc.list(
  list(theta = coda::mcmc(c1b),
       theta = coda::mcmc(c2b)))
rhat2 <- coda::gelman.diag(chains)
# bayesplot::mcmc_trace(chains)

g2 <- ggplot(data = data.frame(
  time = rep(seq_len(B), length.out = 2*B),
  chain = c(c1b, c2b),
  group = factor(rep(c(1,2), each = B))),
  mapping = aes(x = time, y = chain, col = group)) +
  geom_line() +
  scale_color_manual(values = MetBrewer::met.brewer("Renoir", 3)[c(2:3)]) +
  labs(x = "iteration number", y = "") +
  theme_classic() +
  theme(legend.position = "none")

g1 + g2
```

Generally, it is preferable to run a single chain for a longer period than run multiple chains sequentially, as there is a cost to initializing multiple times with different starting values since we must discard initial draws. With parallel computations, multiple chains are more frequent nowadays.


:::{#def-thinning}

## Thinning

MCMC algorithms are often run thinning the chain (i.e., keeping only a fraction of the samples drawn, typically every $k$ iteration). This is wasteful as we can of course get more precise estimates by keeping all posterior draws, whether correlated or not. The only argument in favor of thinning is limited storage capacity: if we run very long chains in a model with hundreds of  parameters, we may run out of memory.

:::


### Posterior predictive checks

Posterior predictive checks can be used to compare models of varying complexity. One of the visual diagnostics, outlined in @Gabry:2019, consists in computing a summary statistic of interest from the posterior predictive (whether mean, median, quantile, skewness, etc.) which is relevant for the problem at hand and which we hope our model can adequately capture. These should be salient features of the data, and may reveal inadequate likelihood or prior information.


Suppose we have $B$ draws from the posterior and simulate for each $n$ observations from the posterior predictive $p(\widetilde{\boldsymbol{y}} \mid \boldsymbol{y})$: we can benchmark summary statistics from our original data $\boldsymbol{y}$ with the posterior predictive copies $\widetilde{\boldsymbol{y}}_b.$ @fig-posterior-pred-check shows this for the two competing models and highlight the fact that the simpler model is not dispersed enough. Even the more complex model struggles to capture this additional heterogeneity with the additional variables. One could go back to the drawing board and consider a negative binomial model.


```{r}
#| eval: true
#| echo: false
#| warning: false
#| message: false
#| cache: true
#| label: fig-posterior-pred-check
#| fig-cap: "Posterior predictive checks for the standard deviation (top) and density of posterior draws (bottom) for hierarchical Poisson model with individual effects (left) and simpler model with only conditions (right)."

g1 <- ggplot(data = data.frame(med= apply(postpred1, 2, sd)),
             mapping =aes(x=med)) +
  geom_histogram(mapping = aes(y = ..density..)) +
  geom_vline(xintercept = median(smartwatch$nviolation)) +
  scale_y_continuous(expand = expansion(mult = c(0,0.1))) +
  labs(x = "std. dev of number of violations", y = "") +
  theme_classic()
g2 <-  ggplot(data = data.frame(med= apply(postpred2, 2, sd)),
             mapping =aes(x=med)) +
  geom_histogram(mapping = aes(y = ..density..)) +
  geom_vline(xintercept = median(smartwatch$nviolation)) +
  scale_y_continuous(expand = expansion(mult = c(0,0.1))) +
  labs(x = "std. deviation of number of violations", y = "") +
  theme_classic()
library(bayesplot)
pp_check.foo <- function(object, type = c("multiple", "overlaid"), ...) {
  type <- match.arg(type)
  y <- object[["y"]]
  yrep <- object[["yrep"]]
  stopifnot(nrow(yrep) >= 50)
  samp <- sample(nrow(yrep), size = ifelse(type == "overlaid", 50, 5))
  yrep <- yrep[samp, ]

  if (type == "overlaid") {
    ppc_dens_overlay(y, yrep, ...) + theme(legend.position = "none")
  } else {
    ppc_hist(y, yrep, ...)+ theme(legend.position = "none")
  }
}

color_scheme_set("gray")
postlist <- list(
  y = smartwatch$nviolation,
  yrep = postpred1)
class(postlist) <- "foo"
g3 <- pp_check(postlist,
  type = "overlaid") + 
theme_classic()
postlist$yrep <- postpred2
g4 <- pp_check(postlist,
  type = "overlaid") + 
theme_classic()
# g3 <- ggplot(data = data.frame(med= apply(postpred1, 2, median)),
#              mapping =aes(x=med)) +
#   geom_histogram(mapping = aes(y = ..density..)) +
#   geom_vline(xintercept = median(smartwatch$nviolation)) +
#   scale_y_continuous(expand = expansion(mult = c(0,0.1))) +
#   labs(x = "median number of violations", y = "") +
#   theme_classic()
# g4 <-  ggplot(data = data.frame(med= apply(postpred2, 2, median)),
#              mapping =aes(x=med)) +
#   geom_histogram(mapping = aes(y = ..density..)) +
#   geom_vline(xintercept = median(smartwatch$nviolation)) +
#   scale_y_continuous(expand = expansion(mult = c(0,0.1))) +
#   labs(x = "median number of violations", y = "") +
#   theme_classic()
(g1 + g2) / (g3 + g4)
# library(brms)
# fitmodel <- brms::brm(nviolation ~ task + (1 | id),
#           family = poisson,
#           data = smartwatch,
#           prior = c(set_prior("normal(0,10)", class = "b"),
#                     set_prior("cauchy(0,3)", class = "sd")),
#           warmup = 1000, iter = 2000, chains = 4, )
waic1 <- round(-mean(apply(loglik_pt1, 2, mean)) +
                 mean(apply(loglik_pt1, 2, var)),2)
waic2 <- round(-mean(apply(loglik_pt2, 2, mean)) +
                 mean(apply(loglik_pt2, 2, var)),2)

```

## Information criteria

The widely applicable information criterion [@Watanabe:2010] is a measure of predictive performance that approximates the cross-validation loss.
Consider first the log pointwise predictive density, defined as the expected value over the posterior distribution $p(\boldsymbol{\theta} \mid \boldsymbol{y}),$
\begin{align*}
\mathsf{LPPD}_i = \mathsf{E}_{\boldsymbol{\theta} \mid \boldsymbol{y}} \left\{ \log p(y_i \mid \boldsymbol{\theta})\right\}.
\end{align*}
The higher the value of the predictive density $\mathsf{LPPD}_i,$ the better the fit for that observation.

As in general information criteria, we sum over all observations, adding a penalization factor that approximates the effective number of parameters in the model, with
\begin{align*}
n\mathsf{WAIC} = -\sum_{i=1}^n \mathsf{LPPD}_i + \sum_{i=1}^n \mathsf{Va}_{\boldsymbol{\theta} \mid \boldsymbol{y}}\{\log p(y_i \mid \boldsymbol{\theta})\}
\end{align*}
where we use again the empirical variance to compute the rightmost term. When comparing competing models, we can rely on their values of $\mathsf{WAIC}$ to discriminate about the predictive performance. To compute $\mathsf{WAIC},$ we need to store the values of the log density of each observation, or at least minimally [compute the running mean and variance accurately](https://www.johndcook.com/blog/standard_deviation/) pointwise at storage cost $\mathrm{O}(n).$ Note that Section 7.2 of @Gelman:2013 define the widely applicable information criterion as $2n \times \mathsf{WAIC}$  to make on par with other information criteria, which are defined typically on the deviance scale and so that lower values correspond to higher predictive performance.

An older criterion  which has somewhat fallen out of fashion is the **deviance** information criterion of @Spiegelhalter:2002. It is defined as
\begin{align*}
\mathsf{DIC} = -2 \ell(\widetilde{\boldsymbol{\theta}}) + 2 p_D
\end{align*}
where $p_D$ is the posterior expectation of the deviance relative to the point estimator of the parameter $\widetilde{\boldsymbol{\theta}}$ (e.g., the maximum a posteriori or the posterior mean)
\begin{align*}
p_D = \mathsf{E}\{D(\boldsymbol{\theta}, \widetilde{\boldsymbol{\theta}}) \mid \boldsymbol{y}\}= \int 2 \{ \ell(\widetilde{\boldsymbol{\theta}}) - \ell(\boldsymbol{\theta})\} f(\boldsymbol{\theta} \mid \boldsymbol{y}) \mathrm{d} \boldsymbol{\theta}
\end{align*}
The DIC can be easily evaluated by keeping track of the log likelihood evaluated at each posterior draw from a Markov chain Monte Carlo algorithm. The penalty term $p_D$ is however not invariant to reparametrizations. Assuming we can derive a multivariate Gaussian approximation to the MLE under suitable regularity conditions, the $\mathsf{DIC}$ is equivalent in large samples to $\mathsf{AIC}.$ The $\mathsf{DIC}$ is considered by many authors as not being a Bayesian procedure; see @Spiegelhalter:2014 and the discussion therein. 


Criteria such as $\mathsf{LPPD}$ and therefore $\mathsf{WAIC}$ require some form of exchangeability, and don't apply to cases where leave-one-out cross validation isn't adequate, for example in spatio-temporal models.

:::{#exm-smartwatch-infocriteria}

## Information criteria for smartwatch and Bayesian LASSO

For the smartwatch model, we get a value of `r round(waic1,2)` for the complex model and `r round(waic2,2)`: this suggests an improvement in using individual-specific effects.

```{r}
#| eval: false
#| echo: true
#| label: fn-waic
#' WAIC
#' @param loglik_pt B by n matrix of pointwise log likelihood
WAIC <- function(loglik_pt){
  -mean(apply(loglik_pt, 2, mean)) +  mean(apply(loglik_pt, 2, var))
}
```

We can also look at the predictive performance. For the `diabetes` data application with the Bayesian LASSO with fixed $\lambda,$ the predictive performance is a trade-off between the effective number of parameter (with larger penalties translating into smaller number of parameters) and the goodness-of-fit. @fig-waic-blasso shows that the decrease in predictive performance is severe when estimates are shrunk towards 0, but the model performs equally well for small penalties.

```{r}
#| eval: true
#| echo: false
#| label: load-blasso
load("models/bayesian_lasso.RData")
data(diabetes, package = "lars")
lambdaseq <- exp(seq(-2,3, length.out = 21))
```

```{r}
#| eval: true
#| echo: false
#| label: fig-waic-blasso
#| fig-cap: "Widely applicable information criterion for the Bayesian LASSO problem fitted to the diabetes data, as a function of the penalty $\\lambda.$"
waic <- sapply(bayesian_lasso, function(x){attr(x, "waic")})
ggplot(data = data.frame(penalty =log(lambdaseq),
                         sWAIC = 2*length(diabetes$y)*waic),
       mapping = aes(x = penalty, y = sWAIC)) +
  geom_line() +
  geom_point() +
  geom_vline(xintercept = lambdaseq[which.min(waic)]) +
  labs(x = expression(log(lambda)),
       y = "",
       subtitle = "scaled WAIC") +
  theme_classic()


```

:::

Ideally, one would measure the predictive performance using the leave-one-out predictive distribution for observation $i$ given all the rest, $p(y_i \mid \boldsymbol{y}_{-i}),$ to avoid double dipping --- the latter is computationally intensive to obtain because it would require running $n$ Markov chains with $n-1$ observations each, but we can get a good approximation using importance sampling, as proposed in eq. 25 of Section 7 of @Gelfand.Dey:1994.

:::{#prp-marginal-pred-checks}

## Marginal predictive check

To check the goodness-of-fit, we turn to the posterior predictive distribution. For each posterior draw and each observation, we generate a sample from the posterior predictive, resulting in an $n \times B$ matrix. We can then for each observation $y_i$ compare the latter with the simulated samples $y_{i,b}^{\mathrm{rep}}$ for posterior sample $\boldsymbol{\theta}_b.$ We compute $\Pr(y_i \geq y_{i}^{\mathrm{rep}})$ by Monte Carlo, by looking at the sample proportion that are more extreme.  Values close to zero or one may indicate outliers.

:::

To avoid double dipping, we can check model adequacy by comparing the leave-one-cross validation predictive draws with the observation.

:::{#prp-cv-predictive-dens}

## Cross-validation predictive density

Consider estimation of the leave-one predictive density under the hypothesis that the likelihood factorizes as $L(\boldsymbol{\theta}; \boldsymbol{y}) = \prod_{i=1}^n f_i(y_i; \boldsymbol{\theta});$ where $f_i$ is the density or mass function of the $i$th observation. Then, with weights
\begin{align*}
w_i(\boldsymbol{\theta}) = \frac{p(\boldsymbol{\theta} \mid \boldsymbol{y}_{-i})}{p(\boldsymbol{\theta} \mid \boldsymbol{y})} \stackrel{\boldsymbol{\theta}}{\propto} \frac{1}{f_i(\boldsymbol{\theta} \mid y_i)}
\end{align*} 
we can write the leave-one-out posterior predictive as
\begin{align*}
p(y_i \mid \boldsymbol{y}_{-i}) &= \int_{\boldsymbol{\Theta}} f_i(y_i \mid \boldsymbol{\theta}) p(\boldsymbol{\theta} \mid \boldsymbol{y}_{-i}) \mathrm{d} \boldsymbol{\theta}
\\& = \int_{\boldsymbol{\Theta}} f(y_i \mid \boldsymbol{\theta}, \boldsymbol{y}_{-i}) w_i(\boldsymbol{\theta}) p(\boldsymbol{\theta} \mid \boldsymbol{y}) \mathrm{d} \boldsymbol{\theta}.
\end{align*}
This formula suggests the importance sampling estimator (cf. @prp-importance-sampling) for a sample of size $B$ from the posterior $p(\boldsymbol{\theta} \mid \boldsymbol{y})$
\begin{align*}
\widehat{p}(y_i \mid \boldsymbol{y}_{-i}) = \frac{\sum_{b=1}^B f_i(y_i \mid \boldsymbol{\theta}_b) w_i(\boldsymbol{\theta}_b)}{\sum_{b=1}^Bw_i(\boldsymbol{\theta}_b)}  = B \left\{\sum_{b=1}^B \frac{1}{f_i (y_i \mid \boldsymbol{\theta}_b)}\right\}^{-1}.
\end{align*}
This estimator takes the form of an harmonic mean, which can have very large variance due to some weights dominating the fit. @Vehtari.Gelman.Gabry:2017 proposed using Pareto smoothed importance sampling [@Vehtari.Simpson.Gelman.Yao.Gabry:2025] to avoid overly large weights; this method is implemented in the `loo` **R** package.

Suppose we have matrices of size $n \times B$ containing the posterior predictive draws $y_{i,b}^{\mathrm{rep}}$ associated with each posterior vector $\boldsymbol{\theta}_b$ and the weights $w_{i,b} = 1/f_i (y_i \mid \boldsymbol{\theta}_b)$ from the importance sampling estimator. We can then compute the probability integral transform with importance sampling
\begin{align*}
\widehat{p}_i^{\mathrm{loo}} = \Pr(y_i^{\mathrm{rep}} \leq y_i \mid \boldsymbol{y}_{-i}) \approx \frac{\sum_{b=1}^B \mathrm{I}(y_i^{\mathrm{rep}} \leq y_i)w_{i,b}}{\sum_{b=1}^B w_{i,b}}, \qquad i =1,\ldots, n
\end{align*}
We can then create a probability-probability plot with these values by comparing the $n$ with ordered quantiles with uniform plotting positions. The values  $\widehat{p}_i^{\mathrm{loo}}$ should be  approximately uniform if the model was perfectly calibrated. @fig-loocv-qqplots shows two examples of these. 



```{r}
#| echo: false
#| eval: true
#| label: fig-loocv-qqplots
#| warning: false
#| message: false
#| fig-cap: "Probability-probability plots based on leave-one-out cross validation for model for the Poisson hierarchical model with the individual random effects (left) and without (right)."
bayesplot::color_scheme_set("gray")
loo_test1 <- loo::loo(loglik_pt1, save_psis = TRUE)
g1 <- bayesplot::ppc_loo_pit_qq(
  y = smartwatch$nviolation,
  yrep = postpred1,
  lw = weights(loo_test1$psis_object)
) + theme_classic()
loo_test2 <- loo::loo(loglik_pt2, save_psis = TRUE)
g2 <- bayesplot::ppc_loo_pit_qq(
  y = smartwatch$nviolation,
  yrep = postpred2,
  lw = weights(loo_test2$psis_object)
) + theme_classic()
g1 + g2
```


:::



<!--
Examples

- Meta analysis? Table 5.4 of Gelman, check for data from researchbox

A meta-analysis is a combination of the results of different studies (of the same quantities), aggregated to increase the power. Given some standardized effect size and a measure of it's standard error, we can considered a weighted average. Since studies have different sample size, the more precise ones get assigned a higher weight.

A simple model, following @Gelman:2006, is to assume the effect size is Gaussian and treat the mean and variance as constant if each study is based on sufficient sample so that mean and variance are reliably estimated. We can then model data as a mixed model with a study-specific random effect.
-->

## Computational strategies


The data augmentation strategies considered in @sec-gibbs-da helps to simplify the likelihood and thereby reduce the cost of each iteration. However, latent variables are imputed conditional on current parameter values $\boldsymbol{\theta}_a$: the higher the number of variables, the more the model will concentrate around current values of $\boldsymbol{\theta}_a$, which leads to slow mixing.

There are two main strategies to deal with this problem: blocking the random effects together and simulating them jointly to improve mixing, and marginalizing out over some of the latent variables.

:::{#exm-marginalization-Gauss}

# Marginalization in Gaussian models


To illustrate this fact, consider a hierarchical Gaussian model of the form
\begin{align*}
\boldsymbol{Y} = \mathbf{X}\boldsymbol{\beta} + \mathbf{Z}\boldsymbol{B} + \boldsymbol{\varepsilon}
\end{align*}
where $\mathbf{X}$ is an $n \times p$ design matrix with centered inputs, $\boldsymbol{\beta} \sim \mathsf{Gauss}(\boldsymbol{0}_p, \sigma^2\mathbf{I}_p),$ $\boldsymbol{B}\sim \mathsf{Gauss}_q(\boldsymbol{0}_q, \boldsymbol{\Omega})$ are random effects and $\boldsymbol{\varepsilon} \sim \mathsf{Gauss}_n(\boldsymbol{0}_n, \kappa^2\mathbf{I}_n)$ are independent white noise.

We can write
\begin{align*}
\boldsymbol{Y} \mid \mathbf{\beta}, \boldsymbol{B} &\sim \mathsf{Gauss}_n(\mathbf{X}\boldsymbol{\beta} + \mathbf{Z}\boldsymbol{B},  \sigma^2\mathbf{I}_p)\\
\boldsymbol{Y} \mid \mathbf{\beta} &\sim \mathsf{Gauss}_n(\mathbf{X}\boldsymbol{\beta}, \mathbf{Q}^{-1}),
\end{align*}
where the second line corresponds to marginalizing out the random effects $\boldsymbol{B}.$ This reduces the number of parameters to draw, but the likelihood evaluation is more costly due to $\mathbf{Q}^{-1}$.
If, as is often the case, $\boldsymbol{\Omega}^{-1}$ and $\mathbf{Z}$ are sparse matrices, the full precision matrix can be efficiently computed using Shermann--Morisson--Woodbury identity as
\begin{align*}
\mathbf{Q}^{-1} &=   \mathbf{Z}\boldsymbol{\Omega}^{-1}\mathbf{Z}^\top + \kappa^2 \mathbf{I}_n,\\
\kappa^2\mathbf{Q} & = \mathbf{I}_n - \mathbf{Z} \boldsymbol{G}^{-1} \mathbf{Z}^\top,\\
\boldsymbol{G} &= \mathbf{Z}^\top\mathbf{Z} + \kappa^2 \boldsymbol{\Omega}^{-1}
\end{align*}
Section 3.1 of @Nychka:2015 details efficient ways of calculating the quadratic form involving $\mathbf{Q}$ and it's determinant.

:::


:::{#prp-pseudo-marginal}

## Pseudo marginal

Another option proposed by @Andrieu.Roberts:2009 based on an original idea from @Beaumont:2003 relies on pseudo marginalization, where integration is done via Monte Carlo sampling. Specifically, suppose that we are ultimately interested in $$p(\boldsymbol{\theta})= \int p(\boldsymbol{\theta}, \boldsymbol{z}) \mathrm{d} \boldsymbol{z},$$ but that for this purpose we normally sample from both parameters. Given a proposal $\boldsymbol{\theta}$ and $q_1(\boldsymbol{\theta})$ and subsequently $L$ draws once from $q_2(\boldsymbol{z} \mid \boldsymbol{\theta})$ for the nuisance, we can approximate the marginal using, e.g.,  importance sampling as
\begin{align*}
\widehat{p}(\boldsymbol{\theta}; \boldsymbol{z}) = \frac{1}{L} \sum_{l=1}^L \frac{p(\boldsymbol{\theta}, \boldsymbol{z}_l)}{q_2(\boldsymbol{z}_l, \boldsymbol{\theta})}.
\end{align*}
We then run a Markov chain on an augmented state space $\boldsymbol{\Theta} \times \mathcal{Z}^L$, with Metropolis--Hastings acceptance ratio of 
\begin{align*}
\frac{\widehat{p}(\boldsymbol{\theta}^{\star}; \boldsymbol{z}_{1,t}^{\star}, \boldsymbol{z}_{L,t}^{\star})}{
\widehat{p}(\boldsymbol{\theta}_t; \boldsymbol{z}_{1,t-1}, \ldots, \boldsymbol{z}_{L, t-1})}\frac{q_1(\boldsymbol{\theta}_{t-1} \mid \boldsymbol{\theta}^{\star}_t)}{q_1(\boldsymbol{\theta}^{\star}_t \mid \boldsymbol{\theta}_{t-1})}.
\end{align*}
Note that the terms involving $\prod_{l=1}^L q_2(\boldsymbol{z}_{l}; \boldsymbol{\theta})$ do not appear because they cancel out, as they are also part of the augmented state space likelihood.


The remarkable feature of the pseudo marginal approach is that even if our average approximation $\widehat{p}$ to the marginal is noisy, the marginal posterior of this Markov chain is the same as the original target.

Compared to regular data augmentation, we must store the full vector $\boldsymbol{z}^{\star}_1, \ldots, \boldsymbol{z}^{\star}_L$  and perform $L$ evaluations of the augmented likelihood. The values of $\boldsymbol{z}$, if accepted, are stored for the next evaluation of the ratio.

The idea of pseudo-marginal extends beyond the user case presented above, as as long as we have an unbiased non-negative estimator of the likelihood $\mathsf{E}\{\widehat{p}(\boldsymbol{\theta})\}=p(\boldsymbol{\theta})$, even when the likelihood itself is intractable. This is useful for models where we can approximate the likelihood by simulation, like for particle filters. Pseudo marginal MCMC algorithms are notorious for yielding sticky chains.

:::

:::{#prp-blocking}

## Blocking

When parameters of the vector $\boldsymbol{\theta}$ that we wish to sample are strongly correlated, it is advisable when possible to simulate them jointly. Because the unnormalized posterior is evaluated at each step conditional on all values, the Markov chain will be making incremental moves and mix slowly if we sample them one step at a time.

:::

Before showcasing the effect of blocking and joint updates, we present another example of data augmentation using @exm-probit-regression.

:::{#exm-Tokyo-rainfall}

## Tokyo rainfall

We consider data from @Kitagawa:1987 that provide a binomial time series giving the number of days in years 1983 and 1984 (a leap year) in which there was more than 1mm of rain in Tokyo. These data and the model we consider are discussed in in section 4.3.4 of @Rue.Held:2005. We thus have $T=366$ days and $n_t \in \{1,2\}$ $(t=1, \ldots, T)$ the number of observations in day $t$ and $y_t=\{0,\ldots, n_t\}$ the number of days with rain. The objective is to obtain a smoothed probability of rain. The underlying probit model considered takes $Y_t \mid n_t, p_t \sim \mathsf{binom}(n_t, p_t)$ and $p_t = \Phi(\beta_t).$

We specify the random effects $\boldsymbol{\beta} \sim \mathsf{Gauss}_{T}(\boldsymbol{0}, \tau^{-1}\mathbf{Q}^{-1}),$ where $\mathbf{Q}$ is a $T \times T$ precision matrix that encodes the local dependence. A circular random walk structure of order 2 is used to model the smooth curves by smoothing over neighbors, and enforces small second derivative. This is a suitable prior because it enforces no constraint on the mean structure. This amounts to specifying the process with
\begin{align*}
\Delta^2\beta_t &= (\beta_{t+1} - \beta_t) - (\beta_t - \beta_{t-1})
\\&=-\beta_{t-1} +2 \beta_t - \beta_{t+1} \sim \mathsf{Gauss}(0, \tau^{-1}), \qquad t \in \mathbb{N} \mod 366.
\end{align*}
This yields an intrinsic Gaussian Markov random field with a circulant precision matrix $\tau\mathbf{Q}=\tau\mathbf{GG^\top}$ of rank $T-1,$ where
\begin{align*}
\mathbf{G} &=
\begin{pmatrix}
2 & -1 & 0 & 0 & \cdots & -1\\
-1 & 2 & -1 & 0 & \ddots & 0 \\
0 & -1 & 2 & -1 & \ddots & 0 \\
\vdots & \ddots & \ddots  & \ddots  & \ddots  & \vdots \\
-1 & 0 & 0 & 0 & \cdots & 2
\end{pmatrix},
\\
\mathbf{Q} &=
\begin{pmatrix}
6 & -4 & 1 & 0 & \cdots & 1 & -4\\
-4 & 6 & -4 & 1 & \ddots & 0 & 1 \\
1 & -4 & 6 & -4 & \ddots & 0 & 0 \\
\vdots & \ddots & \ddots  & \ddots  & \ddots  & \ddots & \vdots \\
-4 & 1 & 0 & 0 & \cdots & -4 & 6
\end{pmatrix}.
\end{align*}
Because of the linear dependency, the determinant of $\mathbf{Q}$ is zero. The contribution from the latent mean parameters is multivariate Gaussian and we exploit for computations the sparsity of the precision matrix $\mathbf{Q}.$ @fig-CRW2-prior shows five draws from the prior model, which loops back between December 31st and January 1st, and is rather smooth.

```{r}
#| eval: true
#| echo: false
#| fig-cap: "Five realizations from the cyclical random walk Gaussian prior of order 2."
#| label: fig-CRW2-prior
nt <- 366
Q <- hecbayes::crw_Q(d = 366, type = "rw2", sparse = TRUE)
set.seed(1234)
samps <- solve(Matrix::chol(Q), matrix(rnorm(5*366), ncol = 5))
matplot(scale(samps, scale = FALSE), 
        bty = "l",
        ylab = "",
 xlab = "day of year",
type = "l", 
col = RColorBrewer::brewer.pal(n = 5, name = "Blues"),lwd = seq(2, 1, length.out = 5))

```

We can perform data augmentation by imputing Gaussian variables, say $\{z_{t,i}\}$ following @exm-probit-regression from truncated Gaussian, where $z_{t,i} = \beta_t + \varepsilon_{t,i}$ and $\varepsilon_{t,i} \sim \mathsf{Gauss}(0,1)$ are independent standard Gaussian and 
\begin{align*}
z_{t,i} \mid  y_{t,i}, \beta_t \sim 
\begin{cases}
\mathsf{trunc. Gauss}(\beta_t, 1, -\infty, 0) & y_{t,i} = 0 \\
\mathsf{trunc. Gauss}(\beta_t, 1,  0, \infty) & y_{t,i} =1 
\end{cases}
\end{align*}
The posterior is proportional to
\begin{align*}
p(\boldsymbol{\beta} \mid \tau)p(\tau)\prod_{t=1}^{T}\prod_{i=1}^{n_t}p(y_{t,i} \mid z_{t,i}) p(z_{t,i} \mid \beta_t)
\end{align*}
and once we have imputed the Gaussian latent vectors, we can work directly with the values of $z_t = \sum_{i=1}^{n_t} z_{i,t}.$ The posterior then becomes
\begin{align*}
p(\boldsymbol{\beta}, \tau) &\propto \tau^{(n-1)/2}\exp \left( - \frac{\tau}{2} \boldsymbol{\beta}^\top \mathbf{Q} \boldsymbol{\beta}\right)\tau^{a-1}\exp(-\tau b)\\& \quad \times \exp\left\{ - \frac{1}{2} (\boldsymbol{z}/\boldsymbol{n} - \boldsymbol{\beta})^\top \mathrm{diag}(\boldsymbol{n})(\boldsymbol{z}/\boldsymbol{n} - \boldsymbol{\beta})\right\} 
\end{align*}
where $\boldsymbol{z} = (z_1, \ldots, z_T).$
Completing the quadratic form shows that 
\begin{align*}
\boldsymbol{\beta} \mid \boldsymbol{z}, \tau &\sim \mathsf{Gauss}_T\left[\left\{\tau \mathbf{Q} + \mathrm{diag}(\boldsymbol{n})\right\}^{-1} \boldsymbol{z}, \left\{\tau \mathbf{Q} + \mathrm{diag}(\boldsymbol{n})\right\}^{-1}\right]\\
\tau \mid \boldsymbol{\beta} & \sim \mathsf{gamma}\left( \frac{n-1}{2} + a, \frac{\boldsymbol{\beta}^\top \mathbf{Q}\boldsymbol{\beta}}{2} + b \right)
\end{align*}




```{r}
#| eval: true
#| echo: true
library(Matrix)
library(TruncatedNormal)
data(tokyorain, package = "hecbayes")
# Aggregate data
tokyo <- tokyorain |> 
   dplyr::group_by(day) |>
   dplyr::summarize(y = sum(y), n = dplyr::n())
nt <- 366L
# Circulant random walk of order two precision matrix
Q <- hecbayes::crw_Q(d = nt, type = "rw2", sparse = TRUE)
# Sparse Cholesky root
cholQ <- Matrix::chol(Q)
N <- Matrix::Diagonal(n = nt, x = tokyo$n)
# Create containers
B <- 1e4L # number of draws
beta_s <- matrix(nrow = B, ncol = nt)
x_s <- matrix(nrow = B, ncol = nt)
tau_s <- numeric(B)
# Initial values
beta <- rep(0, nt)
tau <- 1000
# Hyperprior parameter values
tau_a <- 1
tau_b <- 0.0001
# Gibbs sampling
for(b in seq_len(B)){
  # Step 1: data augmentation
  x <- TruncatedNormal::rtnorm(
    n = 1,  mu = beta[tokyorain$day], sd = 1,
    lb = ifelse(tokyorain$y == 0, -Inf, 0),
    ub = ifelse(tokyorain$y == 0, 0, Inf))
  tx <- aggregate(x = x, by = list(tokyorain$day), FUN = sum)$x
  x_s[b,] <- tx
  # Step 2: Simulate random effects in block
  beta <- beta_s[b,] <- c(hecbayes::rGaussQ(
    n = 1,
    b = tx, 
    Q = tau * Q + N))
# Simulate precision
  tau <- tau_s[b] <- rgamma(
    n = 1, 
    shape = (nt-1)/2 + tau_a, 
    rate = 0.5*as.numeric(crossprod(cholQ %*% beta)) + tau_b)
  # if beta is VERY smooth, then precision is large
}
```

```{r}
#| eval: true
#| echo: false
#| label: fig-tokyo-post1
#| fig-cap: "Trace plots (top) and correlograms (bottom) for two parameters of the Gibbs sampler for the Tokyo rainfall data, with block updates."
colnames(beta_s) <- paste0("beta", 1:nt)                
post_tokyo1 <- data.frame(cbind(tau = tau_s, beta_s))
write.csv(
    post_tokyo1,
    file = "data/tokyo_mcmc1.csv", 
    row.names = FALSE)
bayesplot::color_scheme_set("gray")
bayesplot_theme_set(theme_classic())
post1 <- posterior::as_draws(post_tokyo1[-(1:100),1:2])
A1 <- bayesplot::mcmc_trace(post1, 
   pars = c("beta1", "tau"), 
   transformations = list("tau" = "log"))
A2 <- bayesplot::mcmc_acf(post1, 
   pars = c("beta1","tau")) 
A1 / A2
```

```{r}
#| eval: true
#| echo: false
#| label: fig-rainfall
#| fig-cap: "Tokyo rainfall fitted median probability with 50% and 89% pointwise credible intervals as a function of time of the year, with the proportion of days of rain (points)."
quants <- apply(pnorm(beta_s), 2, quantile, 
                probs = c((1-0.89)/2, 0.25, 0.5, 0.75, 0.89 + (1-0.89)/2))
matplot(x = 1:nt, 
        y = t(quants), 
        type = "l", 
        lty = c(3,2,1,2,3), 
        col = c("gray90","gray50","black","gray50","gray90"),
        xlab = "day of year", 
        ylab = expression(Phi(beta[t])), 
        bty = "l",
        ylim = c(0,1),
        yaxs = "i")
with(tokyo, points(x = day, y = y/2, pch = 20,cex = 0.1)) 
```


```{r}
#| eval: false
#| echo: false
## NOTE: this seemingly doesn't work with Q not full rank
# Simulate from Gauss(Qinv * b, Qinv) # Rue (2001), alg. 3.1.2
rIGMRF <- function(n, Q, rank){
  nt <- nrow(Q)
  if(missing(rank)){
    rank <- as.integer(rankMatrix(Q, method = "qr"))
  }
  nz <- nt - rank
  lambda <- eigen(Q, symmetric = TRUE, only.values = TRUE)$values[-((rank+1):nt)]
  y <- diag(c(rep(0, nz), rep(1, rank))) %*% 
    c(rep(0, nz), 
      rnorm(n = length(lambda), 
            sd = 1/sqrt(lambda)))
}
```

:::

:::{#exm-blocking-rainfall}

## Blocking 


We revisit @exm-Tokyo-rainfall with two modifications: imputing one parameter $\beta_t$ at a time using random scan Gibbs step, which leads to slower mixing but univariate updates, and a joint update that first draws $\tau^{\star}$ from some proposal distribution, then sample conditional on that value generates the $\boldsymbol{\beta}$ vector and proposes acceptance using a Metropolis step.

A different (less efficient) strategy would be to simulate the $\beta_t$ terms one at a time using a random scan Gibbs, i.e., picking $t_0 \in \{1, \ldots, 366\}$ and looping over indices. This yields higher autocorrelation between components than sampling by block.

```{r}
#| label: code-block
#| eval: false
#| echo: true
  # Compute mean vector for betas
  mbeta <- Matrix::solve(a = tau*Q + N, b = tx)
  # weights of precision for neighbours
  nw <- c(1, -4, -4, 1)
  # Sample an index at random
  st <- sample.int(nt, 1)
  for(i in (st + seq_len(nt)) %% nt + 1L){
   # Indices of the non-zero entries for row Q[i,]
  nh <- c(i-3, i-2, i, i+1) %% 366 + 1
  prec <- tau * 6 + tokyo$n[i]
  condmean <- mbeta[i] - sum(nw*(beta[nh] - mbeta[nh])) * tau / prec
    beta[i] <- rnorm(n = 1, mean = condmean, sd = 1/sqrt(prec))
  }
  beta_s[b,] <- beta
```



```{r}
#| eval: true
#| echo: false
#| cache: true
# Initial values
beta <- rep(0, nt)
tau <- 1000
# Gibbs sampling
for(b in seq_len(B)){
  # if(b %% 100L == 0L){print(paste(b, 'iterations completed')); }
  # Step 1: data augmentation
  x <- TruncatedNormal::rtnorm(
    n = 1,  mu = beta[tokyorain$day], sd = 1,
    lb = ifelse(tokyorain$y == 0, -Inf, 0),
    ub = ifelse(tokyorain$y == 0, 0, Inf))
  tx <- aggregate(x = x, by = list(tokyorain$day), FUN = sum)$x
  x_s[b,] <- tx
  ## Step 2 b: alternative 
  ## Update individually looping over indices
  st <- sample.int(nt, 1)
  # Compute mean vector for betas
  mbeta <- Matrix::solve(a = tau*Q + N, b = tx)
  nw <- c(1, -4, -4, 1)
  for(i in (st + seq_len(nt)) %% nt + 1L){
  # Sample an index at random
  st <- sample.int(nt, 1)
   # Indices of the non-zero entries for row Q[i,]
  nh <- c(i-3, i-2, i, i+1) %% 366 + 1
  prec <- tau * 6 + tokyo$n[i]
  condmean <- mbeta[i] - tau * sum(nw*(beta[nh] - mbeta[nh])) / prec
    beta[i] <- rnorm(n = 1, mean = condmean, sd = 1/sqrt(prec))
    # beta[i] <- hecbayes::rcondmvnorm(
    #   n = 1, 
    #   value = beta,
    #   ind = i, 
    #   mean = mbeta,  
    #   precision = tau* Q + N)
    
  }
  beta_s[b,] <- beta

# Simulate precision
  tau <- tau_s[b] <- rgamma(
    n = 1, 
    shape = (nt-1)/2 + tau_a, 
    rate = 0.5*as.numeric(crossprod(cholQ %*% beta)) + tau_b)
}
post_tokyo2 <- data.frame(cbind(tau_s, beta_s))
colnames(post_tokyo2) <- c("tau", paste0("beta", 1:366))
write.csv(
    post_tokyo2,
    file = "data/tokyo_mcmc2.csv", 
    row.names = FALSE)
```


```{r}
#| eval: true
#| echo: false
#| label: fig-tokyo-post2
#| fig-cap: "Trace plots (top) and correlograms (bottom) for two parameters of the Gibbs sampler for the Tokyo rainfall data, with individual updates for $\\beta_t$."
post_tokyo2 <- read.csv("data/tokyo_mcmc2.csv", header = TRUE)
post2 <- posterior::as_draws(post_tokyo2[-(1:100),1:2])
A1 <- bayesplot::mcmc_trace(post2, 
   pars = c("beta1", "tau"), 
   transformations = list("tau" = "log"))
A2 <- bayesplot::mcmc_acf(post2, 
   pars = c("beta1","tau"), lags = 500) 
A1 / A2
```

Instead of making things worst, we can try to improve upon our initial sampler by simulating first a proposal $\tau^{\star}$ using a random walk Metropolis (on the log scale) or some other proposal $q(\tau^{\star}; \tau),$ then drawing from the full conditional $\boldsymbol{\beta} \mid \boldsymbol{z}, \tau^{\star}$ and accepting/rejecting the whole move. In doing this, all terms that depend on $\boldsymbol{\beta}$ cancel out, and the term $p(\tau^{\star}, \boldsymbol{\beta}^{\star} \mid \tau)/\{q(\tau^{\star}; \tau)p(\boldsymbol{\beta}^{\star} \mid \tau^{\star})\}$ in the acceptance ratio becomes
\begin{align*}
\frac{\tau_t^{\star(n-1)/2} p(\tau_t^{\star})\exp \left\{-\frac{1}{2}\boldsymbol{z}^\top(\boldsymbol{z}/\boldsymbol{n})\right\}}{q(\tau^{\star}; \tau) \left| \tau^{\star}\mathbf{Q} + \mathrm{diag}(\boldsymbol{n})\right|\exp \left[-\frac{1}{2}\boldsymbol{z}^\top \left\{\tau^{\star}\mathbf{Q} + \mathrm{diag}(\boldsymbol{n})\right\}^{-1}\boldsymbol{z}\right]}
\end{align*}




A second alternative is to ditch altogether the data augmentation step and write the unnormalized log posterior for $\boldsymbol{\beta}$ as
\begin{align*}
 \log p(\boldsymbol{\beta} \mid \boldsymbol{y}) \stackrel{\boldsymbol{\beta}}{\propto} - \frac{\tau}{2} \boldsymbol{\beta}^\top \mathbf{Q} \boldsymbol{\beta} + \sum_{t=1}^{366} y_{t} \log \Phi(\beta_t) + (n_t-y_{t}) \log\{1-\Phi(\beta_t)\}
\end{align*}
and do a quadratic approximation to the posterior by doing a Taylor expansion of the terms $\log p(y_{t} \mid \beta_{t})$ around the current value of the draw for $\boldsymbol{\beta}.$ Given that observations are conditionally independent, we have a sum of independent terms $\ell(\boldsymbol{y}; \boldsymbol{\beta}) = \sum_{t=1}^{366}\log p(y_t \mid \beta_t)$ and this yields, expanding around $\boldsymbol{\beta}^0$, the Gaussian Markov field proposal
\begin{align*}
q(\boldsymbol{\beta} \mid \tau, \boldsymbol{\beta}^0)  \sim \mathsf{Gauss}_{366}\left[\ell'(\boldsymbol{\beta}^0), \tau\mathbf{Q} + \mathrm{diag}\{\ell''(\boldsymbol{\beta}^0)\}\right].
\end{align*}
Indeed, because of conditional independence, the $j$th element of $\ell'$ and $\ell''$ are
\begin{align*}
\ell'(\boldsymbol{\beta}^0)_j  = \left. \frac{\partial \ell(y_j; \beta_j)}{\partial \beta_j}\right|_{\beta_j = \beta_j^0}, \quad \ell''(\boldsymbol{\beta}^0)_j  = \left. \frac{\partial^2 \ell(y_j; \beta_j)}{\partial \beta_j^2}\right|_{\beta_j = \beta_j^0}.
\end{align*}
We can then simulate $\tau$ using an random walk step, then propose $\boldsymbol{\beta}$ conditional on this value using the Gaussian approximation above and accept/reject the pair $(\tau, \boldsymbol{\beta})$ using a Metropolis step. As for the Metropolis-adjusted Langevin algorithm, we need to compute the backward move for the acceptance ratio. We refer to Section 4.4.1 of @Rue.Held:2005 for more details.

:::

Strong dependence can be fixed by blocking (often via forward sampling), but perhaps conterintuitively also be adding additional redundant parameters. @Gelman:2013 consider a simple hierarchical random effect model in which the range of the random effects is severely constrained by the variance.

:::{#exm-parameter-expansion}

## Parameter expansion


Consider a one-way ANOVA with a single observation per group, where for $i=1, \ldots, n,$ we have
\begin{align*}
Y_{i} &\sim \mathsf{Gauss}(\mu + \alpha_i, s^2_i) \\
\alpha_i &\sim \mathsf{Gauss}(0, \sigma^2_\alpha)
\end{align*}
and an improper prior for the mean $p(\mu) \propto 1.$ If there are $K$ groups, then the group-specific mean is $\mu+\alpha_k$, and there is a redundant parameter. In the Bayesian setting, the parameters are weakly identifiable because of the prior on $\boldsymbol{\alpha}$, but the geometry is such that $\alpha_k \to 0$ as $\sigma^2_{\alpha} \to 0.$ See [Section 5.5](https://users.aalto.fi/~ave/BDA3.pdf) on p. 119 of @Gelman:2013 for more details.

We can improve mixing by adding the redundant parameter $\nu$ [@Gelman.vanDyk:2008] common to each observation
\begin{align*}
Y_{i} &\sim \mathsf{Gauss}(\mu + \nu\xi_i, s^2_i) \\
\xi_i &\sim \mathsf{Gauss}(0, \sigma^2_\xi)
\end{align*}
so that $\alpha_j = \nu \xi_j$ and $\sigma_\alpha = |\nu|\sigma_\xi.$ The common parameter $\nu$ controls both  the variance and the amplitude of the coefficients.



Consider the eight school data from Educational Testing Service (ETS), featured prominently in @Gelman:2013. The data shows results of randomized experiments in eight different schools to estimate the effect of coaching on SAT-V scores.
The data consist of estimated treatment mean difference $y_1, \ldots, y_8$ and their standard errors $\sigma_1, \ldots, s_8$. The data size are large, so the average treatment effect (ATE) can be considered Gaussian and the school-specific standard errors $s_j$ are treated as a known quantity.

```{r}
#| eval: true
#| echo: false

# Eight school data
es <- data.frame(school = LETTERS[1:8], 
                 y = c(28, 8, -3, 7, -1, 1, 18, 12), 
                 se = c(15, 10, 16, 11, 9, 11, 10, 18))
n <- nrow(es)
B <- 1e3L
set.seed(80601)
# Starting values
alpha <- rnorm(0, sd = 0.01)
mu <- mean(es$y)
sigma_al <- sqrt(var(es$y) - mean(es$se))
pars1 <- matrix(NA, nrow = B, ncol = n + 2)
var_mu <- 1/sum(1/es$se^2)
for(b in seq_len(B)){
  var_al <- 1/(1/es$se^2 + 1/sigma_al^2)
  pars1[b, 1:n] <- alpha <- rnorm(n = n, mean = var_al * (es$y - mu)/es$se^2, sd = sqrt(var_al))
  pars1[b, n + 1] <- mu <- rnorm(n = 1, mean = var_mu * sum((es$y - alpha)/es$se^2), sd = sqrt(var_mu)) 
  pars1[b, n + 2] <- sigma_al <- sum(alpha^2) / rchisq(1, df = n - 1) 
}

## Sampler 2
# Same model, with joint updates
set.seed(80601)
# Starting values
alpha <- rnorm(0, sd = 0.01)
mu <- mean(es$y)
sigma_al <- sqrt(var(es$y) - mean(es$se))
pars2 <- matrix(NA, nrow = B, ncol = n + 2)
for(b in seq_len(B)){
  var_al <- 1/(1/es$se^2 + 1/sigma_al^2)
  # Sample from joint of alpha, mu
  # by taking p(alpha | sigma_al, y) * p(mu | alpha, sigma_al, y)
  pars2[b, 1:n] <- alpha <- rnorm(n = n, mean = var_al * es$y/es$se^2, sd = sqrt(var_al))
  pars2[b, n + 1] <- mu <- rnorm(n = 1, mean = var_mu * sum((es$y - alpha)/es$se^2), sd = sqrt(var_mu)) 
  pars2[b, n + 2] <- sigma_al <- sum(alpha^2) / rchisq(1, df = n - 1) 
}

# Parameter expansion - V+PX sampler
a <- 1
pars3 <- matrix(NA, nrow = B, ncol = n + 3)
for(b in seq_len(B)){
  var_al <- 1/(1/es$se^2 + 1/sigma_al^2)
  # Sample from joint of alpha, mu
  # by taking p(alpha | sigma_al, y) * p(mu | alpha, sigma_al, y)
  alpha_st <- rnorm(n = n, mean = var_al * es$y/es$se^2, sd = sqrt(var_al))
  pars3[b, n + 1] <- mu <- rnorm(n = 1, mean = var_mu * sum((es$y - alpha)/es$se^2), sd = sqrt(var_mu)) 
  pars3[b, n + 2] <- sigma_al_st <- sum(alpha_st^2) / rchisq(1, df = n - 1) 
  pars3[b, n + 3] <- a <- rnorm(n = 1, mean = sum(alpha_st*(es$y-mu)/es$se^2)/sum(alpha_st^2/es$se^2), 
                                sd = sqrt(sum(alpha_st^2/es$se^2)))
  pars3[b, 1:n] <- alpha_st*a
  pars3[b, n + 2] <- sigma_al <- abs(a)*sigma_al_st
}
```


We can devise different Gibbs sampling from this problem. The naive Gibbs sampler, which iterates between conditionals of $p(\boldsymbol{\alpha} \mid \boldsymbol{y}, \boldsymbol{s}^2, \mu, \sigma^2_{\alpha})$ and $p(\mu \mid \boldsymbol{y}, \boldsymbol{s}^2, \boldsymbol{\alpha})$ leads to strong autocorrelation. A better strategy is to marginalize over the global mean $\mu$ and simulate from $p(\boldsymbol{\alpha} \mid \boldsymbol{y}, \boldsymbol{s}^2, \sigma^2_{\alpha})$ instead. We get then the conditionals
\begin{align*}
\alpha_i \mid y_i, s_i^2, \sigma^2_{\alpha} &\sim \mathsf{Gauss}\left\{ \left(s^{-2}_i + \sigma^{-2}_{\alpha}\right)^{-1}\frac{y_i}{s^2_j}, \left(s^{-2}_i + \sigma^{-2}_{\alpha}\right)^{-1}\right\}\\
\mu \mid \boldsymbol{y}, \boldsymbol{s}^2, \boldsymbol{\alpha} & \sim \mathsf{Gauss}\left( s^2_{\mu} \sum_{j=1}^8 \frac{y_i-\alpha_i}{s^2_j}, s^2_{\mu}\right)\\
\sigma^2_{\alpha} \mid \boldsymbol{\alpha} &\sim \mathsf{inv. gamma}\left( \frac{n-1}{2}, \frac{\sum_{j=1}^8 \alpha_j^2}{2}\right)
\end{align*}
where $s^{-2}_{\mu} =\sum_{j=1}^8 s_j^{-2}.$

The parameter expansion sampler proceeds in exactly the same way with the same conditionals for $\sigma_{\xi}^2$ and $\boldsymbol{\xi}$ as above; the only additional step is 
\begin{align*}
\nu \mid \boldsymbol{y}, \boldsymbol{s}^2, \boldsymbol{\xi} & \sim \mathsf{Gauss}\left\{ \left( \sum_{j=1}^8 \xi_j^2/s_j^2\right)^{-1} \sum_{j=1}^8 \xi_j(y_j-\mu)/s^2_j, \left( \sum_{j=1}^8 \xi_j^2/s_j^2\right)^{-1}\right\}.
\end{align*}
After each update, we then save the progress of  $\alpha_j = \nu \xi_j$ and $\sigma_\alpha = |\nu|\sigma_\xi,$ as the other parameters are not identifiable on their own. The redundant parametrization allows one to more efficiently explore the space. @fig-funnel shows that many regions with small variance are not explored after 1000 iterations of the Gibbs sampler. The geometry exhibited by @fig-funnel is typical of hierarchical construction and complicated for more complex solvers like Hamiltonian Monte Carlo, which will report warnings.


```{r}
#| eval: true
#| echo: false
#| label: fig-funnel 
#| fig-cap: "Dependence between random effect and it's variance, showing a funnel pattern. The block Gibbs sample (left) does not explore the whole posterior, whereas the parameter-expansion algorithm (right) does."
# Funnel behaviour
g1 <- ggplot(
  data = data.frame(
   beta2 = c(pars1[,2]), 
   sigma = c(pars1[,n+2])),
  mapping = aes(x = beta2, y = log(sigma))) +
  geom_point() +
  scale_color_grey() +
  scale_y_continuous(limits = c(0, 13)) +
  labs(x = expression(alpha[2]), 
       y = expression("log"~sigma[alpha]),
       caption = "block")  +
  theme_classic()
g2 <- ggplot(
  data = data.frame(
   beta2 = c(pars3[,2]), 
   sigma = c(pars3[,n+2])),
  mapping = aes(x = beta2, y = log(sigma))) +
  geom_point() +
  scale_color_grey() +
  scale_y_continuous(limits = c(0, 13)) +
  labs(x = expression(alpha[2]), 
       y = expression("log"~sigma[alpha]),
       caption = "expansion")  +
  theme_classic()
g1 + g2
```



:::